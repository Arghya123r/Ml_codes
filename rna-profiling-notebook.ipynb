{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ndf_train = pd.read_csv('/kaggle/input/stanford-ribonanza-rna-folding/train_data.csv')\ndf_test = pd.read_csv('/kaggle/input/stanford-ribonanza-rna-folding/test_sequences.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-16T13:12:31.239734Z","iopub.execute_input":"2023-09-16T13:12:31.240105Z","iopub.status.idle":"2023-09-16T13:13:44.654955Z","shell.execute_reply.started":"2023-09-16T13:12:31.240075Z","shell.execute_reply":"2023-09-16T13:13:44.654009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TensorFlow\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\n\n# Plotting\nimport matplotlib.pyplot as plt\nfrom ydata_profiling import ProfileReport\n\n# Matplotlib defaults\nplt.style.use('seaborn-whitegrid')\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\n\n# Model\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False )","metadata":{"execution":{"iopub.status.busy":"2023-09-16T13:13:44.656625Z","iopub.execute_input":"2023-09-16T13:13:44.657176Z","iopub.status.idle":"2023-09-16T13:13:59.243966Z","shell.execute_reply.started":"2023-09-16T13:13:44.657145Z","shell.execute_reply":"2023-09-16T13:13:59.243174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_train.columns:\n    print(col)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T13:13:59.245646Z","iopub.execute_input":"2023-09-16T13:13:59.246729Z","iopub.status.idle":"2023-09-16T13:13:59.254139Z","shell.execute_reply.started":"2023-09-16T13:13:59.246696Z","shell.execute_reply":"2023-09-16T13:13:59.252873Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dat = df_train.sample(frac=0.2, random_state= 42)\nsample_dat.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-16T13:13:59.257169Z","iopub.execute_input":"2023-09-16T13:13:59.258066Z","iopub.status.idle":"2023-09-16T13:14:01.182982Z","shell.execute_reply.started":"2023-09-16T13:13:59.258018Z","shell.execute_reply":"2023-09-16T13:14:01.181815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dat.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T13:14:01.184447Z","iopub.execute_input":"2023-09-16T13:14:01.184949Z","iopub.status.idle":"2023-09-16T13:14:01.218572Z","shell.execute_reply.started":"2023-09-16T13:14:01.184917Z","shell.execute_reply":"2023-09-16T13:14:01.217358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dat.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T13:14:01.219786Z","iopub.execute_input":"2023-09-16T13:14:01.220069Z","iopub.status.idle":"2023-09-16T13:14:05.368381Z","shell.execute_reply.started":"2023-09-16T13:14:01.220043Z","shell.execute_reply":"2023-09-16T13:14:05.367464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def group_split(X, y, group, train_size=0.75):\n    splitter = GroupShuffleSplit(train_size=train_size)\n    train, test = next(splitter.split(X, y, groups=group))\n    return (X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test])","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-09-16T13:14:05.369275Z","iopub.execute_input":"2023-09-16T13:14:05.369510Z","iopub.status.idle":"2023-09-16T13:14:05.374675Z","shell.execute_reply.started":"2023-09-16T13:14:05.369490Z","shell.execute_reply":"2023-09-16T13:14:05.373745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def group_split(X, y, group, train_size=0.75):\n    splitter = GroupShuffleSplit(train_size=train_size)\n    train, test = next(splitter.split(X, y, groups=group))\n    return (X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test])","metadata":{}}]}